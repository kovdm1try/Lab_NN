{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Лабораторная 3\n",
    "\n",
    "**Изучить и реализовать MLP (многослойная искусственная нейронная сеть) для классификации нелинейно разделимых данных.**\n",
    "\n",
    "1. Сгенерируйте данные (любым методом из sklearn.datasets).\n",
    "2. Визуализируйте данные на плоскости.\n",
    "3. Создайте MLP: вход (2 нейрона), скрытый слой (4 нейрона, ReLU), выход (1 нейрон, sigmoid) - можете использовать pytorch / keras\n",
    "4. Разделите данные (80% — обучение, 20% — тест).\n",
    "5. Обучите на 1000 эпох, постройте график потерь.\n",
    "6. Оцените точность на тесте.\n"
   ],
   "id": "ad386fd9a45a85eb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:24:05.651309Z",
     "start_time": "2025-11-14T23:24:00.297656Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./env/lib/python3.13/site-packages (1.7.2)\r\n",
      "Requirement already satisfied: tensorflow in ./env/lib/python3.13/site-packages (2.20.0)\r\n",
      "Collecting plotly\r\n",
      "  Downloading plotly-6.4.0-py3-none-any.whl.metadata (8.5 kB)\r\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./env/lib/python3.13/site-packages (from scikit-learn) (2.3.4)\r\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./env/lib/python3.13/site-packages (from scikit-learn) (1.16.2)\r\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./env/lib/python3.13/site-packages (from scikit-learn) (1.5.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./env/lib/python3.13/site-packages (from scikit-learn) (3.6.0)\r\n",
      "Requirement already satisfied: absl-py>=1.0.0 in ./env/lib/python3.13/site-packages (from tensorflow) (2.3.1)\r\n",
      "Requirement already satisfied: astunparse>=1.6.0 in ./env/lib/python3.13/site-packages (from tensorflow) (1.6.3)\r\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in ./env/lib/python3.13/site-packages (from tensorflow) (25.9.23)\r\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in ./env/lib/python3.13/site-packages (from tensorflow) (0.6.0)\r\n",
      "Requirement already satisfied: google_pasta>=0.1.1 in ./env/lib/python3.13/site-packages (from tensorflow) (0.2.0)\r\n",
      "Requirement already satisfied: libclang>=13.0.0 in ./env/lib/python3.13/site-packages (from tensorflow) (18.1.1)\r\n",
      "Requirement already satisfied: opt_einsum>=2.3.2 in ./env/lib/python3.13/site-packages (from tensorflow) (3.4.0)\r\n",
      "Requirement already satisfied: packaging in ./env/lib/python3.13/site-packages (from tensorflow) (25.0)\r\n",
      "Requirement already satisfied: protobuf>=5.28.0 in ./env/lib/python3.13/site-packages (from tensorflow) (6.33.0)\r\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in ./env/lib/python3.13/site-packages (from tensorflow) (2.32.5)\r\n",
      "Requirement already satisfied: setuptools in ./env/lib/python3.13/site-packages (from tensorflow) (80.9.0)\r\n",
      "Requirement already satisfied: six>=1.12.0 in ./env/lib/python3.13/site-packages (from tensorflow) (1.17.0)\r\n",
      "Requirement already satisfied: termcolor>=1.1.0 in ./env/lib/python3.13/site-packages (from tensorflow) (3.2.0)\r\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in ./env/lib/python3.13/site-packages (from tensorflow) (4.15.0)\r\n",
      "Requirement already satisfied: wrapt>=1.11.0 in ./env/lib/python3.13/site-packages (from tensorflow) (2.0.1)\r\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in ./env/lib/python3.13/site-packages (from tensorflow) (1.76.0)\r\n",
      "Requirement already satisfied: tensorboard~=2.20.0 in ./env/lib/python3.13/site-packages (from tensorflow) (2.20.0)\r\n",
      "Requirement already satisfied: keras>=3.10.0 in ./env/lib/python3.13/site-packages (from tensorflow) (3.12.0)\r\n",
      "Requirement already satisfied: h5py>=3.11.0 in ./env/lib/python3.13/site-packages (from tensorflow) (3.15.1)\r\n",
      "Requirement already satisfied: ml_dtypes<1.0.0,>=0.5.1 in ./env/lib/python3.13/site-packages (from tensorflow) (0.5.3)\r\n",
      "Collecting narwhals>=1.15.1 (from plotly)\r\n",
      "  Downloading narwhals-2.11.0-py3-none-any.whl.metadata (11 kB)\r\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in ./env/lib/python3.13/site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\r\n",
      "Requirement already satisfied: rich in ./env/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (14.2.0)\r\n",
      "Requirement already satisfied: namex in ./env/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.1.0)\r\n",
      "Requirement already satisfied: optree in ./env/lib/python3.13/site-packages (from keras>=3.10.0->tensorflow) (0.17.0)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./env/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.13/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.10.5)\r\n",
      "Requirement already satisfied: markdown>=2.6.8 in ./env/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.10)\r\n",
      "Requirement already satisfied: pillow in ./env/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (12.0.0)\r\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in ./env/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (0.7.2)\r\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in ./env/lib/python3.13/site-packages (from tensorboard~=2.20.0->tensorflow) (3.1.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in ./env/lib/python3.13/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.3)\r\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./env/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (4.0.0)\r\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./env/lib/python3.13/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\r\n",
      "Requirement already satisfied: mdurl~=0.1 in ./env/lib/python3.13/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow) (0.1.2)\r\n",
      "Downloading plotly-6.4.0-py3-none-any.whl (9.9 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.9/9.9 MB\u001B[0m \u001B[31m10.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading narwhals-2.11.0-py3-none-any.whl (423 kB)\r\n",
      "Installing collected packages: narwhals, plotly\r\n",
      "Successfully installed narwhals-2.11.0 plotly-6.4.0\r\n",
      "\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip is available: \u001B[0m\u001B[31;49m24.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m25.3\u001B[0m\r\n",
      "\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n"
     ]
    }
   ],
   "execution_count": 5,
   "source": "!pip install scikit-learn tensorflow plotly",
   "id": "8b3d86368c4a36ac"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-14T23:51:04.681317Z",
     "start_time": "2025-11-14T23:51:04.677695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "import plotly.graph_objects as go"
   ],
   "id": "edb5029d2e4648ee",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:22:45.887363Z",
     "start_time": "2025-11-14T23:22:45.881353Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X, y = make_moons(\n",
    "    n_samples=1000,\n",
    "    random_state=42,\n",
    ")"
   ],
   "id": "1503ec7ecd36c88e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:22:51.856981Z",
     "start_time": "2025-11-14T23:22:51.850324Z"
    }
   },
   "cell_type": "code",
   "source": "X",
   "id": "ec72de213ecdee35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00872719,  0.36817352],\n",
       "       [ 0.921384  , -0.49690497],\n",
       "       [ 0.94022577, -0.49821192],\n",
       "       ...,\n",
       "       [ 1.64091013, -0.26761592],\n",
       "       [-0.91991616,  0.39211512],\n",
       "       [ 0.80079841,  0.59893397]], shape=(1000, 2))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:22:59.418686Z",
     "start_time": "2025-11-14T23:22:59.413893Z"
    }
   },
   "cell_type": "code",
   "source": "y",
   "id": "d98a30c969f3d2a3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:31:53.115619Z",
     "start_time": "2025-11-14T23:31:52.583920Z"
    }
   },
   "cell_type": "code",
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Cluster Visualization',\n",
    "    plot_bgcolor='white',\n",
    "    width=700,\n",
    "    height=600,\n",
    "    xaxis_title='x_0',\n",
    "    yaxis_title='x_1',\n",
    ")\n",
    "\n",
    "idx0 = (y == 0)\n",
    "idx1 = (y == 1)\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=X[idx0, 0],\n",
    "    y=X[idx0, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color='blue'),\n",
    "    name='type 0',\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=X[idx1, 0],\n",
    "    y=X[idx1, 1],\n",
    "    mode='markers',\n",
    "    marker=dict(size=5, color='red'),\n",
    "    name='type 1',\n",
    "))\n",
    "\n",
    "fig.show()"
   ],
   "id": "ed0d43254f77f6b8",
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "marker": {
          "color": "blue",
          "size": 5
         },
         "mode": "markers",
         "name": "type 0",
         "x": {
          "dtype": "f8",
          "bdata": "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"
         },
         "y": {
          "dtype": "f8",
          "bdata": "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"
         },
         "type": "scatter"
        },
        {
         "marker": {
          "color": "red",
          "size": 5
         },
         "mode": "markers",
         "name": "type 1",
         "x": {
          "dtype": "f8",
          "bdata": "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"
         },
         "y": {
          "dtype": "f8",
          "bdata": "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"
         },
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermap": [
           {
            "type": "scattermap",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        },
        "title": {
         "text": "Cluster Visualization"
        },
        "plot_bgcolor": "white",
        "width": 700,
        "height": 600,
        "xaxis": {
         "title": {
          "text": "x_0"
         }
        },
        "yaxis": {
         "title": {
          "text": "x_1"
         }
        }
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:40:22.128681Z",
     "start_time": "2025-11-14T23:40:22.119158Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y,\n",
    ")\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(\n",
    "    X_temp, y_temp,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=y_temp,\n",
    ")"
   ],
   "id": "eefae277576c1ee1",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:40:34.156236Z",
     "start_time": "2025-11-14T23:40:34.152430Z"
    }
   },
   "cell_type": "code",
   "source": "X_train.shape, X_test.shape, X_val.shape",
   "id": "1cb5075e1e1a38b0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((800, 2), (100, 2), (100, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:45:38.483784Z",
     "start_time": "2025-11-14T23:45:38.478540Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def show_class_dist(name, y):\n",
    "    unique, counts = np.unique(y, return_counts=True)\n",
    "    total = len(y)\n",
    "    print(f\"{name}: (total = {total})\")\n",
    "\n",
    "    for cls, cnt in zip(unique, counts):\n",
    "        share = cnt / total\n",
    "        print(f\"  class {cls}: {share:.3f} ({share*100:.1f}%)\")\n",
    "    print()\n",
    "\n",
    "show_class_dist(\"y_train\", y_train)\n",
    "show_class_dist(\"y_val\",   y_val)\n",
    "show_class_dist(\"y_test\",  y_test)\n"
   ],
   "id": "babd38aa045b7bb1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train: (total = 800)\n",
      "  class 0: 0.500 (50.0%)\n",
      "  class 1: 0.500 (50.0%)\n",
      "\n",
      "y_val: (total = 100)\n",
      "  class 0: 0.500 (50.0%)\n",
      "  class 1: 0.500 (50.0%)\n",
      "\n",
      "y_test: (total = 100)\n",
      "  class 0: 0.500 (50.0%)\n",
      "  class 1: 0.500 (50.0%)\n",
      "\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:37:35.625055Z",
     "start_time": "2025-11-14T23:37:35.606293Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = models.Sequential(\n",
    "    [\n",
    "        layers.Input(shape=(2,)),\n",
    "        layers.Dense(4, activation='relu'),\n",
    "        layers.Dense(1, activation='sigmoid'),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-3),\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "\n",
    "model.summary()"
   ],
   "id": "f16612398ba145b2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001B[1mModel: \"sequential_2\"\u001B[0m\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m4\u001B[0m)              │            \u001B[38;5;34m12\u001B[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │             \u001B[38;5;34m5\u001B[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m17\u001B[0m (68.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> (68.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m17\u001B[0m (68.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> (68.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n"
      ],
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:49:02.147753Z",
     "start_time": "2025-11-14T23:48:38.802267Z"
    }
   },
   "cell_type": "code",
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=1000,\n",
    "    validation_data=(X_val, y_val),\n",
    "    verbose=1,\n",
    ")"
   ],
   "id": "ada8523f9fe29ba4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 2/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 737us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 3/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 909us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 4/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 5/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 6/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 7/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 766us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 8/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 904us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 9/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 790us/step - accuracy: 0.8913 - loss: 0.2009 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 10/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 768us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 11/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 12/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 13/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 754us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 14/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 780us/step - accuracy: 0.8913 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 15/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 752us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 16/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2056\n",
      "Epoch 17/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 18/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 19/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8950 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 20/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 757us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 21/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 22/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 23/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 24/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 25/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 26/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 744us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 27/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 28/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 29/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 894us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 30/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 31/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 32/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 943us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 33/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8963 - loss: 0.2012 - val_accuracy: 0.8800 - val_loss: 0.2029\n",
      "Epoch 34/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8938 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2055\n",
      "Epoch 35/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8913 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 36/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 897us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 37/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 897us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 38/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 855us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 39/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 914us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 40/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 854us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 41/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 855us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 42/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 890us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 43/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 966us/step - accuracy: 0.8950 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 44/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 45/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 46/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 745us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 47/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 901us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 48/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 932us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 49/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 822us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 50/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 51/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 756us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 52/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 774us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 53/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2056\n",
      "Epoch 54/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 55/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 777us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 56/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 731us/step - accuracy: 0.8938 - loss: 0.2010 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 57/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 58/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 59/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8963 - loss: 0.2013 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 60/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8963 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 61/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2055\n",
      "Epoch 62/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 63/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 64/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 65/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 66/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 67/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 68/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 69/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8900 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 70/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 71/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 765us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 72/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 73/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 74/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 75/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - accuracy: 0.8913 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 76/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 77/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 78/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 79/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 80/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 81/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 82/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 83/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 734us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 84/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 85/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 86/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 87/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 748us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 88/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 769us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 89/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 756us/step - accuracy: 0.8925 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 90/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 739us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 91/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 92/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8950 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 93/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 754us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 94/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 744us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 95/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8938 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 96/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 97/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 98/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 99/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 100/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 101/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 102/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 103/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 104/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 105/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 106/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 107/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 108/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 109/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 110/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 834us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 111/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 937us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 112/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 911us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 113/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 887us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 114/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 921us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 115/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 951us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 116/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 905us/step - accuracy: 0.8950 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2031\n",
      "Epoch 117/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 921us/step - accuracy: 0.8938 - loss: 0.2009 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 118/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 860us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 119/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 838us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 120/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 849us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 121/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 841us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 122/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 833us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 123/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 852us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 124/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 835us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 125/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 752us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 126/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 127/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 726us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 128/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 736us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 129/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 807us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 130/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 866us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 131/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 857us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 132/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 133/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 782us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 134/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 752us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 135/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 136/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 137/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 138/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 139/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 140/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 735us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 141/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 142/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 143/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 144/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 145/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 146/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 147/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 148/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 149/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 150/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 151/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 734us/step - accuracy: 0.8913 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 152/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 153/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 154/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 155/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 156/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 157/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 771us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 158/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 750us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 159/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 160/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 161/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8950 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 162/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 738us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 163/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8925 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2057\n",
      "Epoch 164/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 739us/step - accuracy: 0.8925 - loss: 0.2011 - val_accuracy: 0.8800 - val_loss: 0.2030\n",
      "Epoch 165/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 166/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 855us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 167/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 168/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 169/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 170/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 731us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 171/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 172/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8913 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 173/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 174/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 175/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 176/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 177/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 178/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 179/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 785us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 180/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 751us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 181/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 748us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 182/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 183/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 184/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 185/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 706us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 186/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 187/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 772us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 188/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 189/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 190/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 191/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 192/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 193/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 194/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 706us/step - accuracy: 0.8963 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 195/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 732us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 196/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 197/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 198/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 199/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 200/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 201/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 783us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 202/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 203/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 204/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 205/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 206/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 207/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 918us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 208/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 932us/step - accuracy: 0.8900 - loss: 0.2012 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 209/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 852us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 210/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 211/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 773us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 212/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 788us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 213/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 214/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8950 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 215/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 216/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 774us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 217/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 218/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 726us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 219/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 220/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 221/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 222/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 223/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 768us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 224/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 225/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 226/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 227/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 741us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 228/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 744us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 229/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 230/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 231/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 232/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 233/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 234/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 726us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 235/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 236/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 734us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 237/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 238/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 239/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 240/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 779us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 241/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 887us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 242/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 880us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 243/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 854us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 244/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 764us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 245/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 246/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 247/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 248/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 755us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 249/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 250/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 790us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 251/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 707us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 252/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 253/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 750us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 254/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 788us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 255/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 256/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 747us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2053\n",
      "Epoch 257/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 754us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 258/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 732us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 259/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 260/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 261/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 262/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 263/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 706us/step - accuracy: 0.8900 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 264/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 265/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 266/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 267/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 735us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 268/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 269/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8938 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 270/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 271/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 272/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 937us/step - accuracy: 0.8913 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 273/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 851us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 274/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 883us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 275/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 883us/step - accuracy: 0.8950 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 276/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 836us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 277/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 876us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 278/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 833us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 279/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8950 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 280/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 849us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 281/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 926us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 282/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 821us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 283/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 284/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 285/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 286/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 790us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 287/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 288/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 289/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 789us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 290/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 760us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 291/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 292/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 293/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8913 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 294/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 295/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 775us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 296/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 751us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 297/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 847us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 298/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 763us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 299/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 788us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 300/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 301/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8913 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 302/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 303/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8913 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 304/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 305/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 306/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 307/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 308/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 766us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2031\n",
      "Epoch 309/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 782us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2053\n",
      "Epoch 310/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 311/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 312/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 313/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 738us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 314/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 737us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 315/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 316/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 742us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 317/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 318/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 319/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 320/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 321/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 322/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 323/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 706us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 324/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8963 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 325/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 734us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 326/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 327/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 328/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8913 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 329/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 330/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 331/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 741us/step - accuracy: 0.8913 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 332/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8950 - loss: 0.2010 - val_accuracy: 0.8800 - val_loss: 0.2031\n",
      "Epoch 333/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 755us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 334/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 335/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 336/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 735us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 337/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 338/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 339/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 340/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2056\n",
      "Epoch 341/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 342/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 748us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 343/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 735us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 344/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 345/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 346/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 347/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 348/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 349/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8950 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 350/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 351/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 352/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 353/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 354/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 355/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 356/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 357/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 358/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 359/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 732us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 360/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 361/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 793us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 362/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 790us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 363/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 732us/step - accuracy: 0.8963 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 364/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 738us/step - accuracy: 0.8963 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 365/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 366/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 367/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2057\n",
      "Epoch 368/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 369/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 370/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 371/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 739us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 372/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 778us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 373/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 374/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 726us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 375/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2056\n",
      "Epoch 376/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 734us/step - accuracy: 0.8913 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 377/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 378/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 379/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 380/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 381/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 382/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 707us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 383/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 384/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 385/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 707us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 386/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 387/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 735us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 388/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 389/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 390/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 391/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 392/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 744us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 393/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 734us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 394/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 395/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8900 - loss: 0.2009 - val_accuracy: 0.8800 - val_loss: 0.2055\n",
      "Epoch 396/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8938 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 397/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 398/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 761us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 399/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 400/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 401/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 707us/step - accuracy: 0.8913 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 402/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2030\n",
      "Epoch 403/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 404/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 405/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 406/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 407/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 739us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 408/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 409/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 410/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 737us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 411/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 412/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 413/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 414/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 415/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 416/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 417/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 418/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 419/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 420/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 421/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 824us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 422/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 707us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 423/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 706us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 424/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8913 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 425/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 426/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 427/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 428/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 760us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 429/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 430/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 431/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 432/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 433/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8950 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 434/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8950 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 435/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 436/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 437/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 438/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 439/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 440/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 441/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 442/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 443/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 762us/step - accuracy: 0.8963 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2031\n",
      "Epoch 444/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 445/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 446/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2055\n",
      "Epoch 447/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8913 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 448/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 449/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 736us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 450/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 783us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 451/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 784us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 452/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 755us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 453/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 760us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 454/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 750us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 455/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 764us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 456/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 457/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 770us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 458/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 706us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 459/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 460/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 461/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 462/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 463/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 464/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 465/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 750us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 466/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 467/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 468/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 707us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 469/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 470/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 471/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 738us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 472/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 706us/step - accuracy: 0.8913 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 473/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 474/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 475/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 476/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 477/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 478/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 479/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8963 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 480/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8963 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 481/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 482/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 483/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 484/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 485/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 486/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 487/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 488/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 782us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 489/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 736us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 490/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 491/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8925 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 492/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 493/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 494/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 495/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 496/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 497/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 498/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 499/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 500/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 501/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 804us/step - accuracy: 0.8913 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 502/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 787us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 503/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 763us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 504/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 788us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 505/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 506/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 808us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 507/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 508/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 774us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 509/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 748us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 510/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 796us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 511/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 512/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 513/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 514/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8913 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 515/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 516/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 753us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 517/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 518/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 519/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8950 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 520/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 521/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8950 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 522/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 523/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 524/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 735us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 525/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 526/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 527/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8913 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 528/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 529/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 530/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 531/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 532/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 754us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 533/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 796us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 534/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 535/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 536/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 537/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 763us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 538/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 761us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 539/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 540/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 541/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 542/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 543/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 544/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 545/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 546/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 547/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 548/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 549/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 748us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 550/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 791us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 551/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 781us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 552/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 757us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 553/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 835us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 554/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 774us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 555/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 764us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 556/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 737us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 557/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 558/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 745us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 559/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 738us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 560/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 751us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 561/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 863us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 562/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 847us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 563/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 749us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 564/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 565/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8950 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 566/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 861us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 567/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 881us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 568/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 898us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 569/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 912us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 570/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 864us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 571/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 572/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 876us/step - accuracy: 0.8925 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 573/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 852us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 574/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 908us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 575/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 759us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 576/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 735us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 577/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 754us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 578/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 579/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 732us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 580/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 737us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 581/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 756us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 582/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 583/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8925 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 584/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 585/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 586/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 587/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 588/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 589/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 797us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 590/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 801us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 591/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 740us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 592/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 763us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 593/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 594/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 595/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 767us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 596/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 597/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 598/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 599/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 752us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 600/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 601/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 602/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 812us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 603/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 739us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 604/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 731us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 605/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 606/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 738us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 607/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 732us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 608/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 609/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 610/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 611/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 612/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 613/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 614/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 615/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 616/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 843us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 617/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 902us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 618/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 856us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 619/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 781us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 620/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 732us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 621/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 622/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 623/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 740us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 624/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 738us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 625/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 846us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 626/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 825us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 627/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 821us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 628/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 749us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 629/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 737us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 630/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 631/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 863us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 632/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 802us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 633/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 845us/step - accuracy: 0.8950 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2055\n",
      "Epoch 634/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 768us/step - accuracy: 0.8925 - loss: 0.2012 - val_accuracy: 0.8800 - val_loss: 0.2027\n",
      "Epoch 635/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 769us/step - accuracy: 0.8938 - loss: 0.2000 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 636/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 734us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 637/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 746us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 638/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 793us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 639/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 640/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 763us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 641/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 736us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 642/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 643/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 644/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 731us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 645/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 888us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 646/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 905us/step - accuracy: 0.8938 - loss: 0.2009 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 647/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 916us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 648/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 799us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 649/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 745us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 650/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 651/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 652/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 653/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 735us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 654/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 655/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 656/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 657/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 658/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 659/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 660/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 744us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 661/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 734us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 662/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 663/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 731us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 664/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 665/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 666/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 667/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 668/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 669/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 670/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 671/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 672/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 673/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 694us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 674/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 675/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 731us/step - accuracy: 0.8938 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2053\n",
      "Epoch 676/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8950 - loss: 0.2010 - val_accuracy: 0.8800 - val_loss: 0.2025\n",
      "Epoch 677/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 678/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 679/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 680/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 681/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 682/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 783us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 683/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 684/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 685/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 686/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 707us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 687/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 688/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 689/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 690/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 691/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 692/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 693/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 694/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 726us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 695/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 696/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8913 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 697/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 698/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 699/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 700/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 701/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 702/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 703/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 878us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 704/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 890us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 705/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 910us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 706/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 750us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 707/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 766us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 708/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 709/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 710/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 711/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 736us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 712/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 713/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 714/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 786us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 715/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 739us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 716/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 717/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 718/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 719/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 720/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 721/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 738us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 722/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 759us/step - accuracy: 0.8963 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 723/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 738us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 724/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 725/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 753us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 726/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 819us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 727/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 767us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 728/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 751us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 729/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 744us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 730/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 748us/step - accuracy: 0.8913 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 731/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 739us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 732/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 771us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 733/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 734/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 720us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 735/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 736/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 742us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 737/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 756us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 738/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 739/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 749us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 740/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 739us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 741/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 742/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 769us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 743/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 730us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 744/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 745/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 746/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 747/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 748/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 805us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 749/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 751us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 750/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 745us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 751/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 742us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 752/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 753/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 754/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 726us/step - accuracy: 0.8950 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 755/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 756/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 753us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 757/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 716us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 758/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 794us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 759/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 792us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 760/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 768us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 761/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 773us/step - accuracy: 0.8938 - loss: 0.2009 - val_accuracy: 0.8800 - val_loss: 0.2055\n",
      "Epoch 762/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 753us/step - accuracy: 0.8950 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 763/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 721us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 764/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 765/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 766/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 736us/step - accuracy: 0.8913 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 767/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 768/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 769/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 770/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 791us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 771/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 888us/step - accuracy: 0.8925 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2052\n",
      "Epoch 772/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 836us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 773/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 765us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2031\n",
      "Epoch 774/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 760us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 775/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 752us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 776/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 709us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 777/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 828us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 778/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 840us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 779/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 800us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 780/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 778us/step - accuracy: 0.8938 - loss: 0.2008 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 781/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 788us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 782/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 784us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 783/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 807us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 784/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 777us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 785/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8913 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 786/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 795us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 787/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 908us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 788/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 855us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 789/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 836us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 790/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 877us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 791/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 787us/step - accuracy: 0.8913 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 792/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 750us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 793/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 816us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 794/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 955us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 795/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 877us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 796/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 881us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 797/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 984us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 798/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 847us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 799/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 826us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 800/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 801/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 802/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 803/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 804/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 841us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 805/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 806/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 807/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 808/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 733us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 809/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 810/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 768us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 811/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 812/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 813/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 814/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 815/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 816/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 817/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 796us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 818/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 819/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 820/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 821/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 822/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 707us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 823/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 824/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 825/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 710us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 826/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 677us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 827/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 828/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 829/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 830/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 750us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 831/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 798us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 832/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 833/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8925 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 834/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 719us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 835/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 836/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 837/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 838/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 839/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 840/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 841/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 842/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 843/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 844/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 845/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 846/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 847/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 848/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 682us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 849/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 850/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 851/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 852/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 853/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 672us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 854/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 771us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 855/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 856/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 750us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 857/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 927us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 858/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 868us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 859/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 870us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 860/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 793us/step - accuracy: 0.8938 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 861/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 862/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 863/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 864/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 865/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 866/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 724us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 867/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 753us/step - accuracy: 0.8963 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 868/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8925 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 869/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 870/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 715us/step - accuracy: 0.8913 - loss: 0.2011 - val_accuracy: 0.8800 - val_loss: 0.2056\n",
      "Epoch 871/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 701us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 872/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2031\n",
      "Epoch 873/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 874/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 727us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 875/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 876/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 762us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 877/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 878/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 879/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 678us/step - accuracy: 0.8938 - loss: 0.2011 - val_accuracy: 0.8800 - val_loss: 0.2030\n",
      "Epoch 880/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - accuracy: 0.8913 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2053\n",
      "Epoch 881/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8925 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 882/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 722us/step - accuracy: 0.8950 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 883/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 725us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 884/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 795us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 885/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 764us/step - accuracy: 0.8913 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 886/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8950 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 887/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 750us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 888/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 889/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 890/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 891/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 892/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 699us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 893/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8925 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 894/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 895/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 896/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 688us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 897/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 731us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 898/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 706us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 899/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 742us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 900/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 901/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 712us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 902/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 718us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 903/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 703us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 904/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 729us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 905/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 906/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 907/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 908/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 687us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 909/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 692us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2028\n",
      "Epoch 910/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 911/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 696us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 912/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 913/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 914/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 757us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 915/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 764us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 916/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 717us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 917/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 704us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 918/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 713us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 919/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 728us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 920/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 754us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 921/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 832us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 922/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 723us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 923/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 924/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 925/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 749us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 926/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 781us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2047\n",
      "Epoch 927/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 825us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 928/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 830us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 929/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 778us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 930/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 744us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 931/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 693us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 932/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 933/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 697us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 934/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 935/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 749us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 936/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 711us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 937/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 743us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 938/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 749us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 939/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 740us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 940/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 686us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 941/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 700us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 942/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 698us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2031\n",
      "Epoch 943/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2031\n",
      "Epoch 944/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 747us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 945/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 799us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 946/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 708us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 947/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 668us/step - accuracy: 0.8913 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2051\n",
      "Epoch 948/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - accuracy: 0.8913 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 949/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 690us/step - accuracy: 0.8925 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 950/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 706us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 951/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 705us/step - accuracy: 0.8925 - loss: 0.2000 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 952/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 681us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2050\n",
      "Epoch 953/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 666us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 954/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 683us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 955/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 695us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 956/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 702us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 957/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 689us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 958/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 676us/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 959/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 685us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 960/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 675us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 961/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 962/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - accuracy: 0.8925 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2039\n",
      "Epoch 963/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 691us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2042\n",
      "Epoch 964/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 679us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 965/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 684us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 966/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 673us/step - accuracy: 0.8963 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 967/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 791us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 968/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 714us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 969/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2041\n",
      "Epoch 970/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 971/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 972/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 935us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 973/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 983us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2035\n",
      "Epoch 974/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 954us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 975/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8925 - loss: 0.2007 - val_accuracy: 0.8800 - val_loss: 0.2056\n",
      "Epoch 976/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 977/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2037\n",
      "Epoch 978/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8950 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2046\n",
      "Epoch 979/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 1ms/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 980/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 923us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 981/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 951us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 982/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 936us/step - accuracy: 0.8938 - loss: 0.2005 - val_accuracy: 0.8800 - val_loss: 0.2031\n",
      "Epoch 983/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 792us/step - accuracy: 0.8938 - loss: 0.2006 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 984/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 803us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2034\n",
      "Epoch 985/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 829us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 986/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 768us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 987/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 795us/step - accuracy: 0.8950 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2033\n",
      "Epoch 988/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 808us/step - accuracy: 0.8913 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2048\n",
      "Epoch 989/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 794us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 990/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 813us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2045\n",
      "Epoch 991/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 740us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 992/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 778us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2032\n",
      "Epoch 993/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 807us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 994/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 785us/step - accuracy: 0.8938 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n",
      "Epoch 995/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 777us/step - accuracy: 0.8938 - loss: 0.2002 - val_accuracy: 0.8800 - val_loss: 0.2044\n",
      "Epoch 996/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 744us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2036\n",
      "Epoch 997/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 746us/step - accuracy: 0.8925 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2040\n",
      "Epoch 998/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 839us/step - accuracy: 0.8938 - loss: 0.2001 - val_accuracy: 0.8800 - val_loss: 0.2043\n",
      "Epoch 999/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 764us/step - accuracy: 0.8938 - loss: 0.2004 - val_accuracy: 0.8800 - val_loss: 0.2049\n",
      "Epoch 1000/1000\n",
      "\u001B[1m25/25\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 786us/step - accuracy: 0.8950 - loss: 0.2003 - val_accuracy: 0.8800 - val_loss: 0.2038\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:49:28.136182Z",
     "start_time": "2025-11-14T23:49:28.112613Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=train_loss,\n",
    "    mode='lines',\n",
    "    name='Train loss'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=val_loss,\n",
    "    mode='lines',\n",
    "    name='Val loss'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Train/Val Loss',\n",
    "    xaxis_title='Эпоха',\n",
    "    yaxis_title='Loss',\n",
    "    width=800,\n",
    "    height=500,\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "id": "55b1f0eb73586b12",
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "Train loss",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000
         ],
         "y": [
          0.20034846663475037,
          0.2004339098930359,
          0.20051757991313934,
          0.20050153136253357,
          0.20036621391773224,
          0.2004328966140747,
          0.20045623183250427,
          0.20059734582901,
          0.2008698284626007,
          0.20043613016605377,
          0.20053882896900177,
          0.20042917132377625,
          0.20042166113853455,
          0.20063932240009308,
          0.2004508525133133,
          0.20077812671661377,
          0.20042948424816132,
          0.2004709243774414,
          0.20058080554008484,
          0.2005465179681778,
          0.20081457495689392,
          0.200408935546875,
          0.20050722360610962,
          0.2003704309463501,
          0.20045727491378784,
          0.20051872730255127,
          0.20049087703227997,
          0.2004479616880417,
          0.20039060711860657,
          0.20056535303592682,
          0.20052748918533325,
          0.20042890310287476,
          0.2011505514383316,
          0.20077766478061676,
          0.20042148232460022,
          0.20046190917491913,
          0.2005341500043869,
          0.20039129257202148,
          0.20048604905605316,
          0.20041833817958832,
          0.20038050413131714,
          0.20043247938156128,
          0.20068994164466858,
          0.2003648728132248,
          0.2005433887243271,
          0.20049844682216644,
          0.20052078366279602,
          0.20057550072669983,
          0.2003849744796753,
          0.20041315257549286,
          0.20040956139564514,
          0.20052535831928253,
          0.20071758329868317,
          0.20036350190639496,
          0.20047502219676971,
          0.20095881819725037,
          0.2005050629377365,
          0.20052564144134521,
          0.20128916203975677,
          0.2002912163734436,
          0.2005428820848465,
          0.20047122240066528,
          0.2004440277814865,
          0.20053443312644958,
          0.20044006407260895,
          0.20034144818782806,
          0.2004152238368988,
          0.20043912529945374,
          0.20077377557754517,
          0.2003709226846695,
          0.20056472718715668,
          0.20055662095546722,
          0.2003801167011261,
          0.20042094588279724,
          0.20052900910377502,
          0.20036998391151428,
          0.2004534900188446,
          0.20054508745670319,
          0.20040391385555267,
          0.2004057914018631,
          0.20045307278633118,
          0.20041288435459137,
          0.20037038624286652,
          0.20039358735084534,
          0.20053745806217194,
          0.20067138969898224,
          0.20038481056690216,
          0.20033420622348785,
          0.20081672072410583,
          0.20044101774692535,
          0.2005700320005417,
          0.20070607960224152,
          0.2003989815711975,
          0.20037195086479187,
          0.20079511404037476,
          0.20047976076602936,
          0.20045804977416992,
          0.20048707723617554,
          0.20038007199764252,
          0.2003861665725708,
          0.2004690021276474,
          0.20038728415966034,
          0.20044252276420593,
          0.20036011934280396,
          0.20042771100997925,
          0.20038047432899475,
          0.2003684788942337,
          0.20060455799102783,
          0.20056508481502533,
          0.20067794620990753,
          0.2005205750465393,
          0.20039363205432892,
          0.20050792396068573,
          0.2007049322128296,
          0.2003481686115265,
          0.20074467360973358,
          0.20090648531913757,
          0.20051813125610352,
          0.20036105811595917,
          0.20040230453014374,
          0.20046623051166534,
          0.2003626823425293,
          0.20034733414649963,
          0.20043674111366272,
          0.20037490129470825,
          0.20050203800201416,
          0.20043769478797913,
          0.2003713846206665,
          0.2003345936536789,
          0.20039749145507812,
          0.20055614411830902,
          0.20044158399105072,
          0.20043504238128662,
          0.20037052035331726,
          0.2003391832113266,
          0.2003900706768036,
          0.20038288831710815,
          0.200388565659523,
          0.2005622237920761,
          0.20036819577217102,
          0.20044219493865967,
          0.2004406601190567,
          0.2003265619277954,
          0.20037779211997986,
          0.20038624107837677,
          0.20050768554210663,
          0.2006065398454666,
          0.20071083307266235,
          0.2002372294664383,
          0.20036113262176514,
          0.2004668265581131,
          0.20062074065208435,
          0.2004743069410324,
          0.20034393668174744,
          0.20051370561122894,
          0.2003827542066574,
          0.2004033923149109,
          0.20036154985427856,
          0.2003811001777649,
          0.20049870014190674,
          0.20062273740768433,
          0.20031307637691498,
          0.20083878934383392,
          0.20107118785381317,
          0.2003796398639679,
          0.20040029287338257,
          0.20036712288856506,
          0.20056410133838654,
          0.20044852793216705,
          0.20035423338413239,
          0.20033606886863708,
          0.20051763951778412,
          0.2004222869873047,
          0.20036658644676208,
          0.2003370225429535,
          0.20034083724021912,
          0.20037615299224854,
          0.2004496157169342,
          0.2003025859594345,
          0.20036758482456207,
          0.2004016637802124,
          0.2006216198205948,
          0.200348362326622,
          0.20036867260932922,
          0.20045337080955505,
          0.20041917264461517,
          0.20041589438915253,
          0.20053166151046753,
          0.20036473870277405,
          0.20042821764945984,
          0.20037980377674103,
          0.20074363052845,
          0.20047374069690704,
          0.20075112581253052,
          0.2003304660320282,
          0.2006129026412964,
          0.20035935938358307,
          0.20038005709648132,
          0.20036792755126953,
          0.2003694772720337,
          0.20036077499389648,
          0.2005230188369751,
          0.20044027268886566,
          0.20030923187732697,
          0.2004624307155609,
          0.20042766630649567,
          0.20031161606311798,
          0.20122958719730377,
          0.20042581856250763,
          0.20035694539546967,
          0.20037220418453217,
          0.20036202669143677,
          0.2004336565732956,
          0.20082610845565796,
          0.2003551423549652,
          0.20035165548324585,
          0.2003164291381836,
          0.2005101442337036,
          0.20043911039829254,
          0.20038537681102753,
          0.20036549866199493,
          0.20035715401172638,
          0.20048892498016357,
          0.20035721361637115,
          0.20054227113723755,
          0.20032264292240143,
          0.2003609538078308,
          0.2004808634519577,
          0.20029661059379578,
          0.20034995675086975,
          0.20031504333019257,
          0.20035211741924286,
          0.20051708817481995,
          0.2004239410161972,
          0.20044808089733124,
          0.20046323537826538,
          0.20036092400550842,
          0.2003411054611206,
          0.2004445642232895,
          0.20056481659412384,
          0.2004295289516449,
          0.20036785304546356,
          0.20060527324676514,
          0.20037175714969635,
          0.20033010840415955,
          0.20040206611156464,
          0.20045965909957886,
          0.20036998391151428,
          0.20042788982391357,
          0.20033694803714752,
          0.2004004716873169,
          0.20045015215873718,
          0.20047515630722046,
          0.20038534700870514,
          0.2003583163022995,
          0.20055131614208221,
          0.20026926696300507,
          0.20049913227558136,
          0.20039093494415283,
          0.20039471983909607,
          0.2003859132528305,
          0.20043326914310455,
          0.20058372616767883,
          0.20026807487010956,
          0.20058225095272064,
          0.20033101737499237,
          0.20039890706539154,
          0.20064178109169006,
          0.2007751613855362,
          0.20024727284908295,
          0.20034390687942505,
          0.20034338533878326,
          0.20030272006988525,
          0.20035792887210846,
          0.20080076158046722,
          0.20046047866344452,
          0.20030073821544647,
          0.20033515989780426,
          0.20058439671993256,
          0.20032653212547302,
          0.20038054883480072,
          0.20030343532562256,
          0.2002817541360855,
          0.2005055546760559,
          0.20041555166244507,
          0.20050039887428284,
          0.20049503445625305,
          0.20029966533184052,
          0.20035560429096222,
          0.20030471682548523,
          0.20027515292167664,
          0.20044662058353424,
          0.20033007860183716,
          0.20034971833229065,
          0.20035457611083984,
          0.20039433240890503,
          0.20034468173980713,
          0.20036280155181885,
          0.20036882162094116,
          0.20037265121936798,
          0.2004384994506836,
          0.20034979283809662,
          0.2006133645772934,
          0.20030683279037476,
          0.2003231793642044,
          0.20034830272197723,
          0.20036587119102478,
          0.20063923299312592,
          0.2005983293056488,
          0.2003008872270584,
          0.2004716545343399,
          0.20050911605358124,
          0.20026996731758118,
          0.2003975659608841,
          0.2004273533821106,
          0.2003723680973053,
          0.2004835158586502,
          0.20034325122833252,
          0.20048931241035461,
          0.2002778798341751,
          0.2002686709165573,
          0.20048074424266815,
          0.20029973983764648,
          0.20055809617042542,
          0.20053429901599884,
          0.20045939087867737,
          0.20041514933109283,
          0.20037338137626648,
          0.20038162171840668,
          0.20028842985630035,
          0.20069235563278198,
          0.20100048184394836,
          0.20048971474170685,
          0.20046907663345337,
          0.20031853020191193,
          0.20030193030834198,
          0.20053191483020782,
          0.20040732622146606,
          0.20032814145088196,
          0.2006269097328186,
          0.20022158324718475,
          0.20033520460128784,
          0.20059651136398315,
          0.2004813700914383,
          0.2004082351922989,
          0.20061317086219788,
          0.20034515857696533,
          0.20042401552200317,
          0.2005944848060608,
          0.20040062069892883,
          0.20032760500907898,
          0.20050187408924103,
          0.2002464085817337,
          0.20026862621307373,
          0.20030729472637177,
          0.20058129727840424,
          0.2003321647644043,
          0.20040445029735565,
          0.2003394067287445,
          0.20032306015491486,
          0.20035851001739502,
          0.2004082351922989,
          0.20059552788734436,
          0.20065033435821533,
          0.20043522119522095,
          0.2003980427980423,
          0.20055687427520752,
          0.20034730434417725,
          0.20035380125045776,
          0.20044150948524475,
          0.20032250881195068,
          0.20032952725887299,
          0.2003840059041977,
          0.2005387544631958,
          0.2004891037940979,
          0.20033688843250275,
          0.20065759122371674,
          0.2002868503332138,
          0.20033317804336548,
          0.20048686861991882,
          0.2003069519996643,
          0.20039382576942444,
          0.200469970703125,
          0.20033958554267883,
          0.2004343867301941,
          0.2003782093524933,
          0.20031234622001648,
          0.20029743015766144,
          0.20030860602855682,
          0.20043988525867462,
          0.20028026401996613,
          0.20037637650966644,
          0.20035988092422485,
          0.20045144855976105,
          0.20087970793247223,
          0.2007906138896942,
          0.2003048062324524,
          0.20032039284706116,
          0.2004285305738449,
          0.20024587213993073,
          0.200805202126503,
          0.20050163567066193,
          0.20053772628307343,
          0.20033080875873566,
          0.2005523443222046,
          0.2005816400051117,
          0.20039144158363342,
          0.20028184354305267,
          0.20026621222496033,
          0.20023684203624725,
          0.20058324933052063,
          0.20042476058006287,
          0.20044083893299103,
          0.20030641555786133,
          0.20045271515846252,
          0.2003021389245987,
          0.20024144649505615,
          0.2002515345811844,
          0.20039840042591095,
          0.20028987526893616,
          0.20036140084266663,
          0.20036467909812927,
          0.20032289624214172,
          0.20049390196800232,
          0.2004709243774414,
          0.2004581242799759,
          0.20020894706249237,
          0.2002944052219391,
          0.20050686597824097,
          0.20018905401229858,
          0.20040123164653778,
          0.20047199726104736,
          0.20064647495746613,
          0.20057670772075653,
          0.20031745731830597,
          0.200239360332489,
          0.20044927299022675,
          0.200416699051857,
          0.20031903684139252,
          0.2002662718296051,
          0.20052267611026764,
          0.2003082036972046,
          0.20080702006816864,
          0.20021477341651917,
          0.2003452330827713,
          0.2005414217710495,
          0.20035062730312347,
          0.2006365954875946,
          0.20052507519721985,
          0.20029117166996002,
          0.20037274062633514,
          0.20031999051570892,
          0.20029108226299286,
          0.20030681788921356,
          0.20049770176410675,
          0.20038269460201263,
          0.2003137767314911,
          0.20046569406986237,
          0.2003539651632309,
          0.20022331178188324,
          0.20041713118553162,
          0.2007116824388504,
          0.20024877786636353,
          0.2002173662185669,
          0.20032791793346405,
          0.2002953588962555,
          0.20030616223812103,
          0.20034244656562805,
          0.20040646195411682,
          0.20028044283390045,
          0.20030927658081055,
          0.2004002183675766,
          0.20030446350574493,
          0.2002790868282318,
          0.20036068558692932,
          0.20032618939876556,
          0.20033365488052368,
          0.2003038227558136,
          0.20040571689605713,
          0.2002653330564499,
          0.20039062201976776,
          0.2003059983253479,
          0.20045819878578186,
          0.20057006180286407,
          0.2003449648618698,
          0.20066194236278534,
          0.20046167075634003,
          0.20042362809181213,
          0.20025001466274261,
          0.20042936503887177,
          0.20072372257709503,
          0.20041295886039734,
          0.2004845291376114,
          0.20061397552490234,
          0.20025098323822021,
          0.20031076669692993,
          0.20069177448749542,
          0.20025691390037537,
          0.20040006935596466,
          0.20049676299095154,
          0.20052357017993927,
          0.2002202868461609,
          0.20029039680957794,
          0.2002694010734558,
          0.20051293075084686,
          0.20022816956043243,
          0.20027557015419006,
          0.20034904778003693,
          0.20033740997314453,
          0.20035114884376526,
          0.20029018819332123,
          0.20032352209091187,
          0.20039242506027222,
          0.20047473907470703,
          0.20020221173763275,
          0.2003389149904251,
          0.2002968043088913,
          0.20037026703357697,
          0.20056524872779846,
          0.20029838383197784,
          0.20066657662391663,
          0.20037534832954407,
          0.2002834528684616,
          0.20032230019569397,
          0.20050841569900513,
          0.20020069181919098,
          0.20040327310562134,
          0.20038582384586334,
          0.2003370225429535,
          0.20039518177509308,
          0.2002696990966797,
          0.2003389149904251,
          0.20021316409111023,
          0.2002706527709961,
          0.20044611394405365,
          0.2003229856491089,
          0.20023809373378754,
          0.20023688673973083,
          0.2004404515028,
          0.20027710497379303,
          0.20033003389835358,
          0.20033593475818634,
          0.20029382407665253,
          0.20028626918792725,
          0.20034830272197723,
          0.20038704574108124,
          0.20034515857696533,
          0.20035403966903687,
          0.2006777971982956,
          0.2003535032272339,
          0.20019516348838806,
          0.20030094683170319,
          0.2003600001335144,
          0.20030832290649414,
          0.2002442479133606,
          0.2002301812171936,
          0.20024971663951874,
          0.20028142631053925,
          0.20028121769428253,
          0.20044240355491638,
          0.2005166858434677,
          0.2005719691514969,
          0.20049035549163818,
          0.20051193237304688,
          0.20061306655406952,
          0.20020073652267456,
          0.20026518404483795,
          0.20040564239025116,
          0.20032614469528198,
          0.2003498077392578,
          0.2003084123134613,
          0.20074276626110077,
          0.20049619674682617,
          0.2002044916152954,
          0.2006368488073349,
          0.20027093589305878,
          0.20029860734939575,
          0.20042754709720612,
          0.20034097135066986,
          0.2002723515033722,
          0.2002757489681244,
          0.2002580314874649,
          0.2006659060716629,
          0.20027437806129456,
          0.20026054978370667,
          0.2002468854188919,
          0.2002442181110382,
          0.2003367394208908,
          0.20044296979904175,
          0.2002517729997635,
          0.20065177977085114,
          0.20046566426753998,
          0.20031575858592987,
          0.20046818256378174,
          0.200314462184906,
          0.20027871429920197,
          0.20031686127185822,
          0.20027263462543488,
          0.2003096640110016,
          0.20029334723949432,
          0.2003300040960312,
          0.20026130974292755,
          0.2002047747373581,
          0.20029817521572113,
          0.20034685730934143,
          0.20030827820301056,
          0.20028381049633026,
          0.2004171907901764,
          0.20026735961437225,
          0.2002774477005005,
          0.20032499730587006,
          0.200264573097229,
          0.2003585249185562,
          0.2002440243959427,
          0.2002900093793869,
          0.2003307342529297,
          0.20027855038642883,
          0.20045757293701172,
          0.20040519535541534,
          0.20038361847400665,
          0.20026354491710663,
          0.20028705894947052,
          0.20023439824581146,
          0.20024266839027405,
          0.2002975046634674,
          0.20024456083774567,
          0.20021118223667145,
          0.20039038360118866,
          0.20018570125102997,
          0.2003118395805359,
          0.2002382129430771,
          0.20036333799362183,
          0.20081648230552673,
          0.20124763250350952,
          0.20003467798233032,
          0.20032739639282227,
          0.20026926696300507,
          0.200343057513237,
          0.20052312314510345,
          0.20022200047969818,
          0.2002839595079422,
          0.20029082894325256,
          0.20029723644256592,
          0.20033344626426697,
          0.20016629993915558,
          0.2008620798587799,
          0.2002117931842804,
          0.20036861300468445,
          0.2003720998764038,
          0.2004682868719101,
          0.2002510130405426,
          0.20040537416934967,
          0.20042499899864197,
          0.2002304494380951,
          0.2004767656326294,
          0.2003832757472992,
          0.20035183429718018,
          0.20023810863494873,
          0.20025165379047394,
          0.20022602379322052,
          0.20026744902133942,
          0.2003147155046463,
          0.20031116902828217,
          0.200282022356987,
          0.20035098493099213,
          0.20031744241714478,
          0.20035748183727264,
          0.20034494996070862,
          0.20022644102573395,
          0.20027779042720795,
          0.20036634802818298,
          0.2005704641342163,
          0.20020295679569244,
          0.20032934844493866,
          0.20081041753292084,
          0.20102527737617493,
          0.20064081251621246,
          0.20038241147994995,
          0.2003471553325653,
          0.20027904212474823,
          0.20026910305023193,
          0.20031586289405823,
          0.20023824274539948,
          0.20063917338848114,
          0.20027311146259308,
          0.20042844116687775,
          0.2001509666442871,
          0.20033933222293854,
          0.20017167925834656,
          0.20035266876220703,
          0.20029638707637787,
          0.20038050413131714,
          0.20030449330806732,
          0.2002805769443512,
          0.20042553544044495,
          0.20066028833389282,
          0.20048803091049194,
          0.20034290850162506,
          0.20051197707653046,
          0.20026397705078125,
          0.2002272605895996,
          0.20040561258792877,
          0.20019686222076416,
          0.20026232302188873,
          0.20030422508716583,
          0.20030151307582855,
          0.20044170320034027,
          0.20015130937099457,
          0.20045223832130432,
          0.20041736960411072,
          0.200521320104599,
          0.2001587301492691,
          0.2002629041671753,
          0.20040731132030487,
          0.20024703443050385,
          0.200170636177063,
          0.20027047395706177,
          0.20024223625659943,
          0.20022287964820862,
          0.20019645988941193,
          0.20027801394462585,
          0.2003144472837448,
          0.20014885067939758,
          0.20041801035404205,
          0.20021198689937592,
          0.20024259388446808,
          0.20030128955841064,
          0.20027108490467072,
          0.20024298131465912,
          0.20038604736328125,
          0.20027834177017212,
          0.2001817673444748,
          0.20018978416919708,
          0.20025789737701416,
          0.20050087571144104,
          0.20029570162296295,
          0.20025384426116943,
          0.2003496140241623,
          0.2002795785665512,
          0.20023351907730103,
          0.2002921998500824,
          0.20019857585430145,
          0.2001897394657135,
          0.2005007565021515,
          0.20039740204811096,
          0.20030628144741058,
          0.20016992092132568,
          0.20020122826099396,
          0.20039959251880646,
          0.20059867203235626,
          0.20025207102298737,
          0.20037372410297394,
          0.20019401609897614,
          0.20052030682563782,
          0.20020730793476105,
          0.2002178430557251,
          0.20016223192214966,
          0.20057496428489685,
          0.20023684203624725,
          0.20030295848846436,
          0.2009127289056778,
          0.2001449465751648,
          0.20046985149383545,
          0.20025119185447693,
          0.200214684009552,
          0.20057004690170288,
          0.20017582178115845,
          0.20026186108589172,
          0.2003064900636673,
          0.20025554299354553,
          0.20052850246429443,
          0.20024654269218445,
          0.2004941999912262,
          0.2005629986524582,
          0.20018085837364197,
          0.2003110647201538,
          0.20033890008926392,
          0.20022782683372498,
          0.20025674998760223,
          0.20078107714653015,
          0.20034807920455933,
          0.2004372477531433,
          0.20027011632919312,
          0.20025596022605896,
          0.20029863715171814,
          0.20018865168094635,
          0.20032121241092682,
          0.2002086043357849,
          0.20030425488948822,
          0.2003215253353119,
          0.20031341910362244,
          0.20023584365844727,
          0.20035037398338318,
          0.2002374827861786,
          0.20029346644878387,
          0.20025821030139923,
          0.20018713176250458,
          0.20021235942840576,
          0.20027585327625275,
          0.2002575844526291,
          0.20033879578113556,
          0.2003643810749054,
          0.20018409192562103,
          0.20039252936840057,
          0.2001529484987259,
          0.20019082725048065,
          0.20035718381404877,
          0.2001577615737915,
          0.20043201744556427,
          0.20030707120895386,
          0.20020267367362976,
          0.20021148025989532,
          0.20028382539749146,
          0.20021429657936096,
          0.20028868317604065,
          0.20017269253730774,
          0.20018808543682098,
          0.20022942125797272,
          0.20024225115776062,
          0.2002442330121994,
          0.20029573142528534,
          0.20031492412090302,
          0.2002720981836319,
          0.2003205120563507,
          0.20043694972991943,
          0.20024989545345306,
          0.2003646045923233,
          0.20016656816005707,
          0.20023313164710999,
          0.20016682147979736,
          0.20028258860111237,
          0.20025652647018433,
          0.20009402930736542,
          0.20045463740825653,
          0.20024259388446808,
          0.20016390085220337,
          0.200126051902771,
          0.20021690428256989,
          0.2002357840538025,
          0.20042093098163605,
          0.20020727813243866,
          0.20023439824581146,
          0.20017939805984497,
          0.2003529667854309,
          0.20021487772464752,
          0.20036330819129944,
          0.2002735584974289,
          0.20031629502773285,
          0.2003379613161087,
          0.20030608773231506,
          0.20031069219112396,
          0.20024748146533966,
          0.2002762407064438,
          0.20036669075489044,
          0.20015816390514374,
          0.20021194219589233,
          0.20019656419754028,
          0.20013324916362762,
          0.20042045414447784,
          0.20068034529685974,
          0.20028817653656006,
          0.20015545189380646,
          0.20015548169612885,
          0.20018652081489563,
          0.20023174583911896,
          0.20019157230854034,
          0.20031651854515076,
          0.2001434713602066,
          0.20020927488803864,
          0.20105904340744019,
          0.20017310976982117,
          0.20027847588062286,
          0.2001737356185913,
          0.2003386914730072,
          0.20021438598632812,
          0.2003549337387085,
          0.2004278153181076,
          0.20027047395706177,
          0.20112203061580658,
          0.2006033957004547,
          0.20014871656894684,
          0.20013605058193207,
          0.2002103477716446,
          0.2001674771308899,
          0.20056451857089996,
          0.20013080537319183,
          0.20026323199272156,
          0.20029939711093903,
          0.20020519196987152,
          0.20024746656417847,
          0.20028425753116608,
          0.20016711950302124,
          0.20059005916118622,
          0.20022793114185333,
          0.20029906928539276,
          0.20019683241844177,
          0.2003675252199173,
          0.20015087723731995,
          0.2002493441104889,
          0.20029869675636292,
          0.20027534663677216,
          0.20023773610591888,
          0.2003285437822342,
          0.2001202404499054,
          0.20024770498275757,
          0.20021924376487732,
          0.20048293471336365,
          0.20014093816280365,
          0.20035871863365173,
          0.20040123164653778,
          0.20024672150611877,
          0.20040404796600342,
          0.20018430054187775,
          0.2002696394920349,
          0.20026254653930664,
          0.20033366978168488,
          0.20029887557029724,
          0.20016615092754364,
          0.20020714402198792,
          0.20023013651371002,
          0.2004074603319168,
          0.20029059052467346,
          0.20035681128501892,
          0.20026199519634247,
          0.20031961798667908,
          0.20054106414318085,
          0.20040157437324524,
          0.20027421414852142,
          0.20022054016590118,
          0.20012179017066956,
          0.20024818181991577,
          0.2001621574163437,
          0.20016364753246307,
          0.20016787946224213,
          0.20016540586948395,
          0.2001902163028717,
          0.20020191371440887,
          0.2003125250339508,
          0.20013992488384247,
          0.20035114884376526,
          0.20011091232299805,
          0.20038053393363953,
          0.20032772421836853,
          0.20010915398597717,
          0.20028910040855408,
          0.2002437561750412,
          0.20027121901512146,
          0.2001747339963913,
          0.2001781463623047,
          0.2005113810300827,
          0.20003600418567657,
          0.20023229718208313,
          0.20028352737426758,
          0.200385183095932,
          0.20023196935653687,
          0.2001722902059555,
          0.20014053583145142,
          0.2004237323999405,
          0.2001831829547882,
          0.20030121505260468,
          0.20020371675491333,
          0.20035915076732635,
          0.20020826160907745,
          0.20033879578113556,
          0.20018760859966278,
          0.200325146317482,
          0.20017379522323608,
          0.20025500655174255,
          0.20020423829555511,
          0.20035819709300995,
          0.2002796232700348,
          0.20023007690906525,
          0.20034092664718628,
          0.2003564089536667,
          0.2006831169128418,
          0.20029224455356598,
          0.2001914381980896,
          0.2003975659608841,
          0.20036868751049042,
          0.20027869939804077,
          0.20030082762241364,
          0.20045453310012817,
          0.20060905814170837,
          0.20032471418380737,
          0.20021967589855194,
          0.20017337799072266,
          0.2002246230840683,
          0.20032930374145508,
          0.20033718645572662,
          0.20021408796310425,
          0.20017507672309875,
          0.20042484998703003,
          0.20015567541122437,
          0.20030798017978668,
          0.2002250701189041,
          0.2003922015428543,
          0.20026713609695435,
          0.20012646913528442,
          0.20036104321479797,
          0.20031161606311798
         ],
         "type": "scatter"
        },
        {
         "mode": "lines",
         "name": "Val loss",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000
         ],
         "y": [
          0.20403242111206055,
          0.2042820304632187,
          0.20397238433361053,
          0.2049950361251831,
          0.20474788546562195,
          0.2046661227941513,
          0.20462779700756073,
          0.2038726806640625,
          0.20458416640758514,
          0.20450258255004883,
          0.20414529740810394,
          0.2039169818162918,
          0.2041306048631668,
          0.20419925451278687,
          0.2046997994184494,
          0.2055540829896927,
          0.20393764972686768,
          0.20403987169265747,
          0.20354227721691132,
          0.20518535375595093,
          0.20376616716384888,
          0.2044631838798523,
          0.20479384064674377,
          0.20474892854690552,
          0.20413079857826233,
          0.20451754331588745,
          0.20511476695537567,
          0.20411473512649536,
          0.20481495559215546,
          0.20436891913414001,
          0.20494216680526733,
          0.20436443388462067,
          0.2029149830341339,
          0.20551009476184845,
          0.204595685005188,
          0.20420941710472107,
          0.2043939083814621,
          0.20438562333583832,
          0.20463243126869202,
          0.20455940067768097,
          0.20407919585704803,
          0.2039044201374054,
          0.20513243973255157,
          0.20371009409427643,
          0.2047712355852127,
          0.20380301773548126,
          0.20423740148544312,
          0.20518256723880768,
          0.20455390214920044,
          0.20438171923160553,
          0.20393233001232147,
          0.20408040285110474,
          0.20564742386341095,
          0.20447683334350586,
          0.2043142467737198,
          0.2035280466079712,
          0.2050168365240097,
          0.2048778384923935,
          0.2032880038022995,
          0.2045893669128418,
          0.20545285940170288,
          0.20434121787548065,
          0.20457756519317627,
          0.20434463024139404,
          0.20472165942192078,
          0.20447415113449097,
          0.20429638028144836,
          0.2038484513759613,
          0.20520025491714478,
          0.20452703535556793,
          0.20372579991817474,
          0.2044195681810379,
          0.20396114885807037,
          0.2040511667728424,
          0.20520782470703125,
          0.20440378785133362,
          0.20432519912719727,
          0.2037026435136795,
          0.2045428305864334,
          0.2046603262424469,
          0.20456844568252563,
          0.20471054315567017,
          0.20406894385814667,
          0.20427972078323364,
          0.20471066236495972,
          0.20382201671600342,
          0.20449058711528778,
          0.204206183552742,
          0.20484806597232819,
          0.20365485548973083,
          0.20465634763240814,
          0.20323936641216278,
          0.20472852885723114,
          0.20424459874629974,
          0.20395788550376892,
          0.20451363921165466,
          0.20452885329723358,
          0.20500798523426056,
          0.2044765055179596,
          0.20426246523857117,
          0.2051616907119751,
          0.20446117222309113,
          0.20366743206977844,
          0.20399925112724304,
          0.2046385407447815,
          0.20405501127243042,
          0.204501211643219,
          0.2043072134256363,
          0.20478641986846924,
          0.20361967384815216,
          0.20432613790035248,
          0.20443153381347656,
          0.2037811428308487,
          0.204757422208786,
          0.20462442934513092,
          0.20312771201133728,
          0.20501506328582764,
          0.2045595496892929,
          0.20427511632442474,
          0.2038210928440094,
          0.2044256031513214,
          0.20459747314453125,
          0.20433348417282104,
          0.20450210571289062,
          0.20413623750209808,
          0.2042643427848816,
          0.20483806729316711,
          0.20436763763427734,
          0.20415300130844116,
          0.2039075344800949,
          0.20507270097732544,
          0.2039833664894104,
          0.20398274064064026,
          0.20457391440868378,
          0.204384446144104,
          0.20448164641857147,
          0.20384381711483002,
          0.20461224019527435,
          0.2048732191324234,
          0.20456115901470184,
          0.20432546734809875,
          0.2048567831516266,
          0.20424145460128784,
          0.20426373183727264,
          0.20436015725135803,
          0.2035125494003296,
          0.204502671957016,
          0.20347416400909424,
          0.20443426072597504,
          0.20480628311634064,
          0.20511890947818756,
          0.20489166676998138,
          0.2039235532283783,
          0.20389190316200256,
          0.20432235300540924,
          0.20458969473838806,
          0.2050100564956665,
          0.2048722207546234,
          0.20416197180747986,
          0.2040378600358963,
          0.20426931977272034,
          0.20452044904232025,
          0.20569734275341034,
          0.20296619832515717,
          0.20435623824596405,
          0.20417900383472443,
          0.20466360449790955,
          0.20390817523002625,
          0.20520702004432678,
          0.20479664206504822,
          0.2045903205871582,
          0.20478609204292297,
          0.20383794605731964,
          0.20434026420116425,
          0.20417776703834534,
          0.20428580045700073,
          0.20400463044643402,
          0.20404256880283356,
          0.20403434336185455,
          0.20459014177322388,
          0.20427650213241577,
          0.2044929563999176,
          0.20384687185287476,
          0.20426517724990845,
          0.2035243809223175,
          0.20432376861572266,
          0.20499874651432037,
          0.2041320651769638,
          0.20475313067436218,
          0.2049158662557602,
          0.2046402394771576,
          0.20323440432548523,
          0.20449428260326385,
          0.20348712801933289,
          0.20497074723243713,
          0.20397229492664337,
          0.20502537488937378,
          0.20456582307815552,
          0.20457430183887482,
          0.20500494539737701,
          0.20480450987815857,
          0.20482206344604492,
          0.2032361477613449,
          0.20402021706104279,
          0.20388446748256683,
          0.20463968813419342,
          0.20457017421722412,
          0.20487242937088013,
          0.20431728661060333,
          0.20408670604228973,
          0.20411519706249237,
          0.204346165060997,
          0.2051525115966797,
          0.20349188148975372,
          0.20438896119594574,
          0.204506054520607,
          0.20442301034927368,
          0.20419937372207642,
          0.20446567237377167,
          0.20442569255828857,
          0.2043732851743698,
          0.20459647476673126,
          0.2038733810186386,
          0.20418788492679596,
          0.20423740148544312,
          0.20423145592212677,
          0.2043745368719101,
          0.2037542313337326,
          0.2043306678533554,
          0.20438724756240845,
          0.20456887781620026,
          0.20428723096847534,
          0.20407497882843018,
          0.2042689323425293,
          0.20429666340351105,
          0.20485563576221466,
          0.20426911115646362,
          0.20416897535324097,
          0.20460593700408936,
          0.20462282001972198,
          0.2036741077899933,
          0.20466171205043793,
          0.20385590195655823,
          0.20481722056865692,
          0.20470286905765533,
          0.2042478322982788,
          0.20417027175426483,
          0.20415760576725006,
          0.20442470908164978,
          0.2046733796596527,
          0.20394544303417206,
          0.20381790399551392,
          0.20450158417224884,
          0.20435021817684174,
          0.2042304426431656,
          0.20529408752918243,
          0.20407982170581818,
          0.20352429151535034,
          0.20420345664024353,
          0.20474109053611755,
          0.20422334969043732,
          0.20337022840976715,
          0.2051125168800354,
          0.20431210100650787,
          0.20485927164554596,
          0.20361146330833435,
          0.2044045329093933,
          0.20439496636390686,
          0.20344772934913635,
          0.2043222039937973,
          0.20516709983348846,
          0.2042708396911621,
          0.20449896156787872,
          0.20405644178390503,
          0.20339159667491913,
          0.20493412017822266,
          0.20471012592315674,
          0.20497842133045197,
          0.20391806960105896,
          0.2044578194618225,
          0.20405049622058868,
          0.2050188183784485,
          0.20445889234542847,
          0.20436516404151917,
          0.20388364791870117,
          0.20422567427158356,
          0.20490334928035736,
          0.2045450359582901,
          0.20445135235786438,
          0.20435883104801178,
          0.20435161888599396,
          0.2039237916469574,
          0.20468798279762268,
          0.20450063049793243,
          0.20437008142471313,
          0.20427751541137695,
          0.20387282967567444,
          0.20481185615062714,
          0.2048422247171402,
          0.20482735335826874,
          0.20477022230625153,
          0.20389418303966522,
          0.2049269825220108,
          0.20424821972846985,
          0.20443594455718994,
          0.20401935279369354,
          0.20386457443237305,
          0.2031324803829193,
          0.20533870160579681,
          0.2042977213859558,
          0.20472528040409088,
          0.20341384410858154,
          0.20406152307987213,
          0.204843670129776,
          0.20365935564041138,
          0.20447507500648499,
          0.20398841798305511,
          0.20412909984588623,
          0.20395441353321075,
          0.20438984036445618,
          0.20488502085208893,
          0.2044542133808136,
          0.2043970823287964,
          0.20440147817134857,
          0.2052345871925354,
          0.2035788893699646,
          0.20455501973628998,
          0.205014169216156,
          0.20451979339122772,
          0.2042860984802246,
          0.2045527994632721,
          0.203059121966362,
          0.20519128441810608,
          0.2041478157043457,
          0.2044629156589508,
          0.20473548769950867,
          0.20357361435890198,
          0.20415429770946503,
          0.204640731215477,
          0.20562446117401123,
          0.20468103885650635,
          0.20368696749210358,
          0.2040240317583084,
          0.204204261302948,
          0.20454208552837372,
          0.20355604588985443,
          0.20414131879806519,
          0.20370666682720184,
          0.20353588461875916,
          0.20489466190338135,
          0.20471777021884918,
          0.2038092166185379,
          0.20425920188426971,
          0.20478734374046326,
          0.20435020327568054,
          0.2046893835067749,
          0.20441219210624695,
          0.2042294293642044,
          0.20393884181976318,
          0.20407649874687195,
          0.20474408566951752,
          0.20452824234962463,
          0.20332875847816467,
          0.20332971215248108,
          0.20454181730747223,
          0.20489385724067688,
          0.2056565284729004,
          0.20493927597999573,
          0.20409609377384186,
          0.20367565751075745,
          0.2036622017621994,
          0.20385830104351044,
          0.2043977975845337,
          0.2040431946516037,
          0.20564329624176025,
          0.2045549899339676,
          0.20444394648075104,
          0.20419132709503174,
          0.20417267084121704,
          0.20389483869075775,
          0.2041817158460617,
          0.20435108244419098,
          0.20457515120506287,
          0.20456713438034058,
          0.20446082949638367,
          0.20422419905662537,
          0.2041170299053192,
          0.2037976086139679,
          0.20410794019699097,
          0.20401810109615326,
          0.20437641441822052,
          0.20485921204090118,
          0.20391975343227386,
          0.20426225662231445,
          0.20549796521663666,
          0.20372648537158966,
          0.20427942276000977,
          0.20423737168312073,
          0.20480182766914368,
          0.20404019951820374,
          0.20504778623580933,
          0.2030143290758133,
          0.20449422299861908,
          0.20391586422920227,
          0.20324987173080444,
          0.20478111505508423,
          0.20411771535873413,
          0.20416785776615143,
          0.20421475172042847,
          0.20446886122226715,
          0.20432309806346893,
          0.20466503500938416,
          0.2047753483057022,
          0.20432288944721222,
          0.20415744185447693,
          0.20404139161109924,
          0.20408819615840912,
          0.20435835421085358,
          0.20422610640525818,
          0.20428399741649628,
          0.204035684466362,
          0.20435220003128052,
          0.20416200160980225,
          0.20501217246055603,
          0.20447370409965515,
          0.20469734072685242,
          0.20389772951602936,
          0.20368839800357819,
          0.20470844209194183,
          0.20375004410743713,
          0.2043176144361496,
          0.20437702536582947,
          0.2033931016921997,
          0.2050122767686844,
          0.20410959422588348,
          0.2037362903356552,
          0.2045927494764328,
          0.20420660078525543,
          0.20471370220184326,
          0.20391975343227386,
          0.2040209174156189,
          0.2040087729692459,
          0.2031317949295044,
          0.20484836399555206,
          0.20443229377269745,
          0.2055240273475647,
          0.2046598643064499,
          0.20328205823898315,
          0.20449337363243103,
          0.20443950593471527,
          0.20369017124176025,
          0.20429456233978271,
          0.20398522913455963,
          0.2041737586259842,
          0.20417606830596924,
          0.20490112900733948,
          0.20449501276016235,
          0.2051677107810974,
          0.2035137563943863,
          0.20411592721939087,
          0.20419441163539886,
          0.2034607082605362,
          0.20420272648334503,
          0.20476940274238586,
          0.2041972577571869,
          0.20403359830379486,
          0.20394475758075714,
          0.204436793923378,
          0.20465365052223206,
          0.20429225265979767,
          0.20474183559417725,
          0.20463843643665314,
          0.20372451841831207,
          0.20413412153720856,
          0.2049226015806198,
          0.20446626842021942,
          0.20428146421909332,
          0.20432333648204803,
          0.2034004181623459,
          0.20461925864219666,
          0.2043495625257492,
          0.204759880900383,
          0.20381425321102142,
          0.2042401134967804,
          0.2036312222480774,
          0.20367324352264404,
          0.2049139440059662,
          0.2042812556028366,
          0.20439019799232483,
          0.2039235681295395,
          0.20524005591869354,
          0.20409610867500305,
          0.20354972779750824,
          0.20523591339588165,
          0.20399488508701324,
          0.20447726547718048,
          0.2033103108406067,
          0.20471645891666412,
          0.2048744559288025,
          0.20448611676692963,
          0.20474033057689667,
          0.20409657061100006,
          0.20387907326221466,
          0.20371247828006744,
          0.2049068957567215,
          0.20423650741577148,
          0.20379525423049927,
          0.20377397537231445,
          0.2043113261461258,
          0.20373451709747314,
          0.20430059731006622,
          0.20423384010791779,
          0.20416393876075745,
          0.20464786887168884,
          0.20390380918979645,
          0.20388373732566833,
          0.20423877239227295,
          0.20383745431900024,
          0.2036653459072113,
          0.2049267441034317,
          0.20431272685527802,
          0.2043602168560028,
          0.20521634817123413,
          0.20421786606311798,
          0.20358513295650482,
          0.20475837588310242,
          0.20496758818626404,
          0.20391987264156342,
          0.20450721681118011,
          0.20418041944503784,
          0.20440655946731567,
          0.20455794036388397,
          0.20429572463035583,
          0.20431236922740936,
          0.20412589609622955,
          0.205004021525383,
          0.20416095852851868,
          0.20397783815860748,
          0.20507919788360596,
          0.2047697901725769,
          0.20403259992599487,
          0.20339572429656982,
          0.20408201217651367,
          0.20421797037124634,
          0.20446234941482544,
          0.20415258407592773,
          0.2044793665409088,
          0.203729510307312,
          0.20378924906253815,
          0.20405691862106323,
          0.20415031909942627,
          0.2039172351360321,
          0.20403069257736206,
          0.2048916220664978,
          0.20418351888656616,
          0.2045123130083084,
          0.20411580801010132,
          0.2045409381389618,
          0.20375801622867584,
          0.20445221662521362,
          0.20335224270820618,
          0.20486381649971008,
          0.20380842685699463,
          0.20500174164772034,
          0.20329442620277405,
          0.20430916547775269,
          0.20476755499839783,
          0.2039792388677597,
          0.20385900139808655,
          0.20486177504062653,
          0.20387762784957886,
          0.205022931098938,
          0.20319804549217224,
          0.20406223833560944,
          0.20497024059295654,
          0.20366603136062622,
          0.20425736904144287,
          0.2046065777540207,
          0.20384052395820618,
          0.20420104265213013,
          0.2037457823753357,
          0.20378339290618896,
          0.20508261024951935,
          0.20412640273571014,
          0.20415546000003815,
          0.20367233455181122,
          0.20376239717006683,
          0.2039579451084137,
          0.20463913679122925,
          0.20454154908657074,
          0.20316803455352783,
          0.20483806729316711,
          0.20417140424251556,
          0.20347702503204346,
          0.20423753559589386,
          0.2043028026819229,
          0.2046261727809906,
          0.20427261292934418,
          0.20383460819721222,
          0.20390094816684723,
          0.20398908853530884,
          0.20429979264736176,
          0.2037162035703659,
          0.20423643290996552,
          0.20378117263317108,
          0.2038465142250061,
          0.20407456159591675,
          0.20499196648597717,
          0.2045394480228424,
          0.20414161682128906,
          0.20422857999801636,
          0.20382562279701233,
          0.20392946898937225,
          0.2037179321050644,
          0.20461353659629822,
          0.20364005863666534,
          0.20428460836410522,
          0.20468315482139587,
          0.20395201444625854,
          0.20425252616405487,
          0.20400011539459229,
          0.20386914908885956,
          0.20441873371601105,
          0.20441532135009766,
          0.20392900705337524,
          0.20391033589839935,
          0.20440368354320526,
          0.20432710647583008,
          0.20390498638153076,
          0.20395135879516602,
          0.20413930714130402,
          0.20385700464248657,
          0.20549747347831726,
          0.20266371965408325,
          0.2036542147397995,
          0.20464342832565308,
          0.20439594984054565,
          0.20476287603378296,
          0.2045510709285736,
          0.20371995866298676,
          0.2045726329088211,
          0.2041076272726059,
          0.2038222700357437,
          0.2038719356060028,
          0.20376956462860107,
          0.204509437084198,
          0.20441095530986786,
          0.2033262997865677,
          0.2048003077507019,
          0.20389169454574585,
          0.20442481338977814,
          0.20350460708141327,
          0.20399878919124603,
          0.20450441539287567,
          0.20408160984516144,
          0.2047768384218216,
          0.20382027328014374,
          0.20430973172187805,
          0.20456087589263916,
          0.20379161834716797,
          0.2035236805677414,
          0.20425653457641602,
          0.20375850796699524,
          0.2043800801038742,
          0.2036668211221695,
          0.20405462384223938,
          0.20466946065425873,
          0.2043861746788025,
          0.20372574031352997,
          0.20422692596912384,
          0.20350871980190277,
          0.20494215190410614,
          0.20428051054477692,
          0.20388036966323853,
          0.20534135401248932,
          0.20254571735858917,
          0.204767644405365,
          0.20374183356761932,
          0.2034156769514084,
          0.2045087218284607,
          0.2040741741657257,
          0.20420022308826447,
          0.20374974608421326,
          0.2048439085483551,
          0.20373918116092682,
          0.20466327667236328,
          0.20380288362503052,
          0.2031978964805603,
          0.20403587818145752,
          0.20425108075141907,
          0.20489700138568878,
          0.20355413854122162,
          0.2047826200723648,
          0.20356632769107819,
          0.20435287058353424,
          0.20321838557720184,
          0.20446239411830902,
          0.20375530421733856,
          0.20317542552947998,
          0.2041207104921341,
          0.20406299829483032,
          0.20412687957286835,
          0.20415683090686798,
          0.20399120450019836,
          0.20415210723876953,
          0.20514275133609772,
          0.2039545476436615,
          0.20405054092407227,
          0.2047535479068756,
          0.20463113486766815,
          0.2052323967218399,
          0.20359909534454346,
          0.2034633755683899,
          0.20454229414463043,
          0.2042016237974167,
          0.2039845585823059,
          0.203202024102211,
          0.20382371544837952,
          0.20428091287612915,
          0.20452642440795898,
          0.2036530077457428,
          0.2036760002374649,
          0.2039908915758133,
          0.2044454962015152,
          0.2045084834098816,
          0.2038385570049286,
          0.20365522801876068,
          0.20415905117988586,
          0.20414337515830994,
          0.2049604207277298,
          0.20459605753421783,
          0.20397453010082245,
          0.2041805237531662,
          0.2043587565422058,
          0.2035485804080963,
          0.20333930850028992,
          0.20410951972007751,
          0.20345279574394226,
          0.20417213439941406,
          0.20424388349056244,
          0.20467902719974518,
          0.2042161524295807,
          0.20381475985050201,
          0.20340107381343842,
          0.20466846227645874,
          0.2039172500371933,
          0.2040078490972519,
          0.2042083591222763,
          0.20344075560569763,
          0.20508281886577606,
          0.2044006735086441,
          0.20343761146068573,
          0.20454318821430206,
          0.20360538363456726,
          0.20417815446853638,
          0.20433993637561798,
          0.20468169450759888,
          0.2031790316104889,
          0.20408281683921814,
          0.204043447971344,
          0.20551513135433197,
          0.20377479493618011,
          0.20406466722488403,
          0.20408421754837036,
          0.20361752808094025,
          0.20482946932315826,
          0.20343537628650665,
          0.2035849243402481,
          0.20339041948318481,
          0.2037319391965866,
          0.2051665186882019,
          0.20417028665542603,
          0.20311233401298523,
          0.2050969898700714,
          0.20457245409488678,
          0.20380835235118866,
          0.2040453404188156,
          0.20378731191158295,
          0.20462173223495483,
          0.2036624550819397,
          0.20443037152290344,
          0.20339877903461456,
          0.20374874770641327,
          0.20487980544567108,
          0.20459583401679993,
          0.20446543395519257,
          0.2038603276014328,
          0.20367811620235443,
          0.20401395857334137,
          0.20481693744659424,
          0.20491962134838104,
          0.2032063603401184,
          0.20316173136234283,
          0.20414817333221436,
          0.2040887326002121,
          0.20360437035560608,
          0.204702228307724,
          0.20375320315361023,
          0.20419330894947052,
          0.20469027757644653,
          0.20426055788993835,
          0.20416966080665588,
          0.20361192524433136,
          0.20463909208774567,
          0.20443958044052124,
          0.20392341911792755,
          0.20361478626728058,
          0.20389719307422638,
          0.20385579764842987,
          0.204965740442276,
          0.20444664359092712,
          0.20348943769931793,
          0.20414422452449799,
          0.20375894010066986,
          0.20350518822669983,
          0.20397444069385529,
          0.2035972625017166,
          0.20435203611850739,
          0.2045905888080597,
          0.2036621868610382,
          0.20438583195209503,
          0.20347684621810913,
          0.20439258217811584,
          0.2036607414484024,
          0.2042103409767151,
          0.20420217514038086,
          0.20396718382835388,
          0.20391273498535156,
          0.20404088497161865,
          0.2040584534406662,
          0.2037706822156906,
          0.20369043946266174,
          0.20434680581092834,
          0.2042999416589737,
          0.2039290815591812,
          0.20409990847110748,
          0.2040337324142456,
          0.20443952083587646,
          0.20432275533676147,
          0.20422224700450897,
          0.20383399724960327,
          0.2039717435836792,
          0.20412050187587738,
          0.20384691655635834,
          0.20447003841400146,
          0.20334692299365997,
          0.20383025705814362,
          0.20393867790699005,
          0.20438548922538757,
          0.204890176653862,
          0.20403355360031128,
          0.20329563319683075,
          0.20415203273296356,
          0.2038242667913437,
          0.20424406230449677,
          0.20381347835063934,
          0.20381732285022736,
          0.20394933223724365,
          0.20431339740753174,
          0.20323923230171204,
          0.2039148360490799,
          0.2046320140361786,
          0.2045213282108307,
          0.2042803019285202,
          0.20401759445667267,
          0.20437729358673096,
          0.2036399096250534,
          0.20443768799304962,
          0.2041899710893631,
          0.205581933259964,
          0.20342151820659637,
          0.20313474535942078,
          0.2036021649837494,
          0.20371152460575104,
          0.20446504652500153,
          0.20511874556541443,
          0.20409440994262695,
          0.20459558069705963,
          0.20298664271831512,
          0.20529590547084808,
          0.2043236792087555,
          0.20393693447113037,
          0.20407164096832275,
          0.20400340855121613,
          0.2044924944639206,
          0.20396988093852997,
          0.2039669156074524,
          0.203582763671875,
          0.20349504053592682,
          0.2034708559513092,
          0.20422202348709106,
          0.20438507199287415,
          0.2037205696105957,
          0.20429793000221252,
          0.20508423447608948,
          0.20473943650722504,
          0.2036091685295105,
          0.20378686487674713,
          0.20421747863292694,
          0.2035088986158371,
          0.20439358055591583,
          0.20393699407577515,
          0.20469340682029724,
          0.2038470208644867,
          0.20381136238574982,
          0.20365995168685913,
          0.20425844192504883,
          0.20387989282608032,
          0.20276927947998047,
          0.20425890386104584,
          0.20356594026088715,
          0.20485123991966248,
          0.20417453348636627,
          0.2039969116449356,
          0.20411041378974915,
          0.20429418981075287,
          0.20333653688430786,
          0.20390644669532776,
          0.20403951406478882,
          0.20410101115703583,
          0.20458295941352844,
          0.2036380022764206,
          0.20453383028507233,
          0.2039678543806076,
          0.20344269275665283,
          0.2046882063150406,
          0.20354312658309937,
          0.2042846530675888,
          0.2037668079137802,
          0.204070582985878,
          0.20403805375099182,
          0.20390209555625916,
          0.20425982773303986,
          0.20390930771827698,
          0.20365433394908905,
          0.20434917509555817,
          0.20413602888584137,
          0.20488499104976654,
          0.2036779522895813,
          0.20458874106407166,
          0.20404091477394104,
          0.20305372774600983,
          0.2031082659959793,
          0.20403383672237396,
          0.2037794142961502,
          0.20359590649604797,
          0.20512615144252777,
          0.2045227289199829,
          0.20401974022388458,
          0.2033270299434662,
          0.2042921781539917,
          0.20497265458106995,
          0.20414075255393982,
          0.2038656771183014,
          0.2045551836490631,
          0.20432476699352264,
          0.20365026593208313,
          0.20456469058990479,
          0.20368890464305878,
          0.2040848284959793,
          0.20397187769412994,
          0.2039012908935547,
          0.20424789190292358,
          0.20451048016548157,
          0.2043095827102661,
          0.20350831747055054,
          0.20360136032104492,
          0.20384831726551056,
          0.20405368506908417,
          0.20340420305728912,
          0.2038251906633377,
          0.20402711629867554,
          0.2035376876592636,
          0.20432545244693756,
          0.20557820796966553,
          0.20361751317977905,
          0.20372097194194794,
          0.20462962985038757,
          0.204445019364357,
          0.2039603739976883,
          0.2044559121131897,
          0.20314352214336395,
          0.204752117395401,
          0.20340128242969513,
          0.2038104236125946,
          0.20358173549175262,
          0.20332130789756775,
          0.20478671789169312,
          0.20358656346797943,
          0.204544335603714,
          0.2044251263141632,
          0.20322547852993011,
          0.20399564504623413,
          0.20381693542003632,
          0.20441721379756927,
          0.20363928377628326,
          0.20399487018585205,
          0.20426982641220093,
          0.20488695800304413,
          0.2037661373615265
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermap": [
           {
            "type": "scattermap",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        },
        "title": {
         "text": "Train/Val Loss"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        },
        "width": 800,
        "height": 500,
        "plot_bgcolor": "white"
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:49:36.732583Z",
     "start_time": "2025-11-14T23:49:36.715752Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loss = history.history['accuracy']\n",
    "val_loss = history.history['val_accuracy']\n",
    "epochs = list(range(1, len(train_loss) + 1))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=train_loss,\n",
    "    mode='lines',\n",
    "    name='Train Accuracy'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=val_loss,\n",
    "    mode='lines',\n",
    "    name='Val Accuracy'\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Train/Val Accuracy',\n",
    "    xaxis_title='Эпоха',\n",
    "    yaxis_title='Loss',\n",
    "    width=800,\n",
    "    height=500,\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ],
   "id": "8867be039b36013d",
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "Train Accuracy",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000
         ],
         "y": [
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8962500095367432,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8962500095367432,
          0.8962500095367432,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8899999856948853,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8912500143051147,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8962500095367432,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.8899999856948853,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8899999856948853,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.8912500143051147,
          0.893750011920929,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8962500095367432,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8962500095367432,
          0.8962500095367432,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8899999856948853,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.8912500143051147,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8912500143051147,
          0.8924999833106995,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8962500095367432,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8962500095367432,
          0.8962500095367432,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8962500095367432,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8912500143051147,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.8962500095367432,
          0.8924999833106995,
          0.893750011920929,
          0.8912500143051147,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8912500143051147,
          0.8924999833106995,
          0.8949999809265137,
          0.8924999833106995,
          0.8924999833106995,
          0.8912500143051147,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8949999809265137,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8924999833106995,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8912500143051147,
          0.8912500143051147,
          0.8924999833106995,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8962500095367432,
          0.893750011920929,
          0.8924999833106995,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.8949999809265137,
          0.8949999809265137,
          0.893750011920929,
          0.8924999833106995,
          0.8924999833106995,
          0.893750011920929,
          0.8949999809265137,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137,
          0.8912500143051147,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.893750011920929,
          0.8924999833106995,
          0.893750011920929,
          0.893750011920929,
          0.8949999809265137
         ],
         "type": "scatter"
        },
        {
         "mode": "lines",
         "name": "Val Accuracy",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350,
          351,
          352,
          353,
          354,
          355,
          356,
          357,
          358,
          359,
          360,
          361,
          362,
          363,
          364,
          365,
          366,
          367,
          368,
          369,
          370,
          371,
          372,
          373,
          374,
          375,
          376,
          377,
          378,
          379,
          380,
          381,
          382,
          383,
          384,
          385,
          386,
          387,
          388,
          389,
          390,
          391,
          392,
          393,
          394,
          395,
          396,
          397,
          398,
          399,
          400,
          401,
          402,
          403,
          404,
          405,
          406,
          407,
          408,
          409,
          410,
          411,
          412,
          413,
          414,
          415,
          416,
          417,
          418,
          419,
          420,
          421,
          422,
          423,
          424,
          425,
          426,
          427,
          428,
          429,
          430,
          431,
          432,
          433,
          434,
          435,
          436,
          437,
          438,
          439,
          440,
          441,
          442,
          443,
          444,
          445,
          446,
          447,
          448,
          449,
          450,
          451,
          452,
          453,
          454,
          455,
          456,
          457,
          458,
          459,
          460,
          461,
          462,
          463,
          464,
          465,
          466,
          467,
          468,
          469,
          470,
          471,
          472,
          473,
          474,
          475,
          476,
          477,
          478,
          479,
          480,
          481,
          482,
          483,
          484,
          485,
          486,
          487,
          488,
          489,
          490,
          491,
          492,
          493,
          494,
          495,
          496,
          497,
          498,
          499,
          500,
          501,
          502,
          503,
          504,
          505,
          506,
          507,
          508,
          509,
          510,
          511,
          512,
          513,
          514,
          515,
          516,
          517,
          518,
          519,
          520,
          521,
          522,
          523,
          524,
          525,
          526,
          527,
          528,
          529,
          530,
          531,
          532,
          533,
          534,
          535,
          536,
          537,
          538,
          539,
          540,
          541,
          542,
          543,
          544,
          545,
          546,
          547,
          548,
          549,
          550,
          551,
          552,
          553,
          554,
          555,
          556,
          557,
          558,
          559,
          560,
          561,
          562,
          563,
          564,
          565,
          566,
          567,
          568,
          569,
          570,
          571,
          572,
          573,
          574,
          575,
          576,
          577,
          578,
          579,
          580,
          581,
          582,
          583,
          584,
          585,
          586,
          587,
          588,
          589,
          590,
          591,
          592,
          593,
          594,
          595,
          596,
          597,
          598,
          599,
          600,
          601,
          602,
          603,
          604,
          605,
          606,
          607,
          608,
          609,
          610,
          611,
          612,
          613,
          614,
          615,
          616,
          617,
          618,
          619,
          620,
          621,
          622,
          623,
          624,
          625,
          626,
          627,
          628,
          629,
          630,
          631,
          632,
          633,
          634,
          635,
          636,
          637,
          638,
          639,
          640,
          641,
          642,
          643,
          644,
          645,
          646,
          647,
          648,
          649,
          650,
          651,
          652,
          653,
          654,
          655,
          656,
          657,
          658,
          659,
          660,
          661,
          662,
          663,
          664,
          665,
          666,
          667,
          668,
          669,
          670,
          671,
          672,
          673,
          674,
          675,
          676,
          677,
          678,
          679,
          680,
          681,
          682,
          683,
          684,
          685,
          686,
          687,
          688,
          689,
          690,
          691,
          692,
          693,
          694,
          695,
          696,
          697,
          698,
          699,
          700,
          701,
          702,
          703,
          704,
          705,
          706,
          707,
          708,
          709,
          710,
          711,
          712,
          713,
          714,
          715,
          716,
          717,
          718,
          719,
          720,
          721,
          722,
          723,
          724,
          725,
          726,
          727,
          728,
          729,
          730,
          731,
          732,
          733,
          734,
          735,
          736,
          737,
          738,
          739,
          740,
          741,
          742,
          743,
          744,
          745,
          746,
          747,
          748,
          749,
          750,
          751,
          752,
          753,
          754,
          755,
          756,
          757,
          758,
          759,
          760,
          761,
          762,
          763,
          764,
          765,
          766,
          767,
          768,
          769,
          770,
          771,
          772,
          773,
          774,
          775,
          776,
          777,
          778,
          779,
          780,
          781,
          782,
          783,
          784,
          785,
          786,
          787,
          788,
          789,
          790,
          791,
          792,
          793,
          794,
          795,
          796,
          797,
          798,
          799,
          800,
          801,
          802,
          803,
          804,
          805,
          806,
          807,
          808,
          809,
          810,
          811,
          812,
          813,
          814,
          815,
          816,
          817,
          818,
          819,
          820,
          821,
          822,
          823,
          824,
          825,
          826,
          827,
          828,
          829,
          830,
          831,
          832,
          833,
          834,
          835,
          836,
          837,
          838,
          839,
          840,
          841,
          842,
          843,
          844,
          845,
          846,
          847,
          848,
          849,
          850,
          851,
          852,
          853,
          854,
          855,
          856,
          857,
          858,
          859,
          860,
          861,
          862,
          863,
          864,
          865,
          866,
          867,
          868,
          869,
          870,
          871,
          872,
          873,
          874,
          875,
          876,
          877,
          878,
          879,
          880,
          881,
          882,
          883,
          884,
          885,
          886,
          887,
          888,
          889,
          890,
          891,
          892,
          893,
          894,
          895,
          896,
          897,
          898,
          899,
          900,
          901,
          902,
          903,
          904,
          905,
          906,
          907,
          908,
          909,
          910,
          911,
          912,
          913,
          914,
          915,
          916,
          917,
          918,
          919,
          920,
          921,
          922,
          923,
          924,
          925,
          926,
          927,
          928,
          929,
          930,
          931,
          932,
          933,
          934,
          935,
          936,
          937,
          938,
          939,
          940,
          941,
          942,
          943,
          944,
          945,
          946,
          947,
          948,
          949,
          950,
          951,
          952,
          953,
          954,
          955,
          956,
          957,
          958,
          959,
          960,
          961,
          962,
          963,
          964,
          965,
          966,
          967,
          968,
          969,
          970,
          971,
          972,
          973,
          974,
          975,
          976,
          977,
          978,
          979,
          980,
          981,
          982,
          983,
          984,
          985,
          986,
          987,
          988,
          989,
          990,
          991,
          992,
          993,
          994,
          995,
          996,
          997,
          998,
          999,
          1000
         ],
         "y": [
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284,
          0.8799999952316284
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermap": [
           {
            "type": "scattermap",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        },
        "title": {
         "text": "Train/Val Accuracy"
        },
        "xaxis": {
         "title": {
          "text": "Эпоха"
         }
        },
        "yaxis": {
         "title": {
          "text": "Loss"
         }
        },
        "width": 800,
        "height": 500,
        "plot_bgcolor": "white"
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:51:08.859174Z",
     "start_time": "2025-11-14T23:51:08.786118Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_pred = (model.predict(X_test) >= 0.5).astype(int)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(\"Точность на тесте:\", acc)"
   ],
   "id": "a3417643bcf7c894",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 5ms/step \n",
      "Точность на тесте: 0.93\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-14T23:54:22.559799Z",
     "start_time": "2025-11-14T23:54:22.510957Z"
    }
   },
   "cell_type": "code",
   "source": [
    "y_test_proba = model.predict(X_test).ravel()\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_test_proba)\n",
    "roc_auc = roc_auc_score(y_test, y_test_proba)\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=fpr,\n",
    "    y=tpr,\n",
    "    mode='lines',\n",
    "    name=f'ROC curve (AUC = {roc_auc:.3f})'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0, 1],\n",
    "    y=[0, 1],\n",
    "    mode='lines',\n",
    "    name='Random',\n",
    "    line=dict(dash='dash')\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='ROC-кривая',\n",
    "    xaxis_title='False Positive Rate',\n",
    "    yaxis_title='True Positive Rate',\n",
    "    width=700,\n",
    "    height=500,\n",
    "    plot_bgcolor='white'\n",
    ")\n",
    "\n",
    "fig.show()\n"
   ],
   "id": "ba5ed7d405ea47e5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m4/4\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "data": [
        {
         "mode": "lines",
         "name": "ROC curve (AUC = 0.978)",
         "x": {
          "dtype": "f8",
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAexSuR+F6pD97FK5H4XqkP7gehetRuK4/uB6F61G4rj97FK5H4Xq0P3sUrkfherQ/uB6F61G4vj+4HoXrUbi+PwAAAAAAAPA/"
         },
         "y": {
          "dtype": "f8",
          "bdata": "AAAAAAAAAAB7FK5H4XqUPwrXo3A9Cuc/CtejcD0K5z9SuB6F61HoP1K4HoXrUeg/mpmZmZmZ6T+amZmZmZnpP7gehetRuO4/uB6F61G47j8AAAAAAADwPwAAAAAAAPA/"
         },
         "type": "scatter"
        },
        {
         "line": {
          "dash": "dash"
         },
         "mode": "lines",
         "name": "Random",
         "x": [
          0,
          1
         ],
         "y": [
          0,
          1
         ],
         "type": "scatter"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "histogram2dcontour": [
           {
            "type": "histogram2dcontour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "choropleth": [
           {
            "type": "choropleth",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "histogram2d": [
           {
            "type": "histogram2d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "heatmap": [
           {
            "type": "heatmap",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "contourcarpet": [
           {
            "type": "contourcarpet",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "contour": [
           {
            "type": "contour",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "surface": [
           {
            "type": "surface",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0.0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1.0,
              "#f0f921"
             ]
            ]
           }
          ],
          "mesh3d": [
           {
            "type": "mesh3d",
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            }
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "parcoords": [
           {
            "type": "parcoords",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolargl": [
           {
            "type": "scatterpolargl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "scattergeo": [
           {
            "type": "scattergeo",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterpolar": [
           {
            "type": "scatterpolar",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "scattergl": [
           {
            "type": "scattergl",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatter3d": [
           {
            "type": "scatter3d",
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermap": [
           {
            "type": "scattermap",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattermapbox": [
           {
            "type": "scattermapbox",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scatterternary": [
           {
            "type": "scatterternary",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "scattercarpet": [
           {
            "type": "scattercarpet",
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            }
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ]
         },
         "layout": {
          "autotypenumbers": "strict",
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "hovermode": "closest",
          "hoverlabel": {
           "align": "left"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "bgcolor": "#E5ECF6",
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "ternary": {
           "bgcolor": "#E5ECF6",
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "sequential": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0.0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1.0,
             "#f0f921"
            ]
           ],
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ]
          },
          "xaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "yaxis": {
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "automargin": true,
           "zerolinewidth": 2
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white",
            "gridwidth": 2
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "geo": {
           "bgcolor": "white",
           "landcolor": "#E5ECF6",
           "subunitcolor": "white",
           "showland": true,
           "showlakes": true,
           "lakecolor": "white"
          },
          "title": {
           "x": 0.05
          },
          "mapbox": {
           "style": "light"
          }
         }
        },
        "title": {
         "text": "ROC-кривая"
        },
        "xaxis": {
         "title": {
          "text": "False Positive Rate"
         }
        },
        "yaxis": {
         "title": {
          "text": "True Positive Rate"
         }
        },
        "width": 700,
        "height": 500,
        "plot_bgcolor": "white"
       },
       "config": {
        "plotlyServerURL": "https://plot.ly"
       }
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 34
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
